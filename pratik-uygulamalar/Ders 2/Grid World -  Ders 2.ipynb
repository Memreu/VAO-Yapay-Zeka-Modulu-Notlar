{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967a7e17-aa67-422c-a220-ff2c103381f9",
   "metadata": {},
   "source": [
    "##  Ders 2 Uygulamas覺: Kendi Evrenini Yarat - Grid World Sim羹lasyonu\n",
    "\n",
    "**Pekitirmeli renme (Reinforcement Learning)** teorisini sadece okumakla kalmay覺p, kendi ellerimizle koda d繹kt羹羹m羹z interaktif bir Python sim羹lasyonu haz覺rlad覺k ! \n",
    "\n",
    "Ders 2 notlar覺nda incelediimiz **\"Grid World (Izgara D羹nyas覺)\"** senaryosunu temel alan bu projede, hi癟bir ey bilmeyen bir yapay zeka ajan覺n覺 (agent) labirente b覺rak覺yor ve hatalar覺ndan ders 癟覺kararak en iyi yolu bulmas覺n覺 izliyoruz.\n",
    "\n",
    "###  Bu Uygulamada Neler Var?\n",
    "\n",
    "Bu kod, sabit bir labirent yerine kurallar覺n覺 tamamen **sizin belirlediiniz** dinamik bir evren sunar:\n",
    "* **Haritay覺 Siz izin:** Izgara boyutunu (rn: 5x5, 10x10) ve ajan覺n balang覺癟 noktas覺n覺 kendiniz belirleyebilirsiniz.\n",
    "* **Tuzaklar覺 ve d羹lleri Yerletirin:** B羹y羹k 繹d羹l羹n ve oyunu bitiren 繹l羹mc羹l tuza覺n yerini se癟erek ajan覺 zorlayabilirsiniz.\n",
    "* **Hareket Maliyetini Ayarlay覺n:** Ajan覺n her ad覺mda yiyecei cezay覺 deitirerek, onun hedefe giden en k覺sa yolu bulmas覺n覺 (veya sonsuza kadar dolanmas覺n覺) salayabilirsiniz.\n",
    "\n",
    "###  Ajan Nas覺l reniyor?\n",
    "\n",
    "1. **Eitim Kamp覺 (Keif ve S繹m羹r羹):** Ajan balang覺癟ta tamamen rastgele hareket ederek 癟evreyi kefeder (Explore) . Zamanla Q-Tablosunu (haf覺zas覺n覺) doldurduk癟a, 繹rendii k璽rl覺 yollar覺 kullanmaya (Exploit) balar .\n",
    "2. **Gecikmeli d羹l (Aggregate Reward):** Ajan anl覺k cezalara tak覺lmadan, oyun sonundaki toplam getirisini maksimize etmeyi 繹renir .\n",
    "3. **G繹rselletirme:** Eitim bittiinde, `matplotlib` ve `seaborn` k羹t羹phaneleri kullan覺larak ajan覺n 癟覺kard覺覺 kusursuz k覺lavuz, yani **\"Optimal Politika\"** ($\\pi^*(s)$) renkli bir harita 羹zerinde y繹n oklar覺yla 癟izdirilir.\n",
    "\n",
    "###  Nas覺l al覺t覺r覺l覺r?\n",
    "\n",
    "1. Bilgisayar覺n覺zda `numpy`, `matplotlib` ve `seaborn` k羹t羹phanelerinin kurulu olduundan emin olun (`pip install numpy matplotlib seaborn`).\n",
    "2. 襤lgili klas繹rdeki `Jupyter Notebook` dosyas覺n覺 癟al覺t覺r覺n.\n",
    "3. Konsolda size sorulan sorulara cevap vererek evreninizi yarat覺n (bo b覺rak覺p Enter'a basarak varsay覺lan kurallar覺 da kullanabilirsiniz).\n",
    "4. Eitimin bitmesini bekleyin ve ajan覺n bulduu k覺rm覺z覺 rotan覺n tad覺n覺 癟覺kar覺n!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe62417-3b7c-4c3f-bf83-0b8195094e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def get_user_input(prompt, default_value):\n",
    "    \"\"\"Kullan覺c覺 'Enter'a bas覺p ge癟erse varsay覺lan deeri atayan minik asistan覺m覺z.\"\"\"\n",
    "    user_input = input(f\"{prompt} (Varsay覺lan: {default_value}): \")\n",
    "    return int(user_input) if user_input.strip() else default_value\n",
    "\n",
    "print(\"--- GRSEL PEK襤T襤RMEL襤 RENME: KEND襤 EVREN襤N襤 OLUTUR ---\")\n",
    "print(\"襤pucu: Sorular覺 bo b覺rak覺p 'Enter'a basarsan覺z standart kurallar ge癟erli olur.\\n\")\n",
    "\n",
    "# --- 1. DNYAYI VE KURALLARI 襤NA ED襤YORUZ ---\n",
    "GRID_SIZE = get_user_input(\"1. Izgara Boyutunu belirleyin (rn: 4, 5, 6)\", 5)\n",
    "NUM_STATES = GRID_SIZE * GRID_SIZE\n",
    "NUM_ACTIONS = 4\n",
    "\n",
    "START_STATE = get_user_input(\"2. Ajan覺n Balang覺癟 Karesi\", 0)\n",
    "GOAL_STATE = get_user_input(\"3. B羹y羹k d羹l羹n (Hedef) Karesi\", NUM_STATES - 1)\n",
    "GOAL_REWARD = get_user_input(\"4. Hedefe Ulama d羹l羹 (Puan)\", 40)\n",
    "SEVERE_TRAP = get_user_input(\"5. B羹y羹k Tuza覺n Karesi (Oyun Bitirici)\", (NUM_STATES // 2) - 1)\n",
    "TRAP_PENALTY = get_user_input(\"6. Tuzaa D羹me Cezas覺 (Eksi Puan olarak)\", -20)\n",
    "LIVING_PENALTY = get_user_input(\"7. Ad覺m Ba覺 Ceza (Hareket Maliyeti)\", -1)\n",
    "\n",
    "# --- 2. AJANIN BEYN襤 (Q-TABLOSU) ---\n",
    "q_table = np.zeros((NUM_STATES, NUM_ACTIONS))\n",
    "\n",
    "# --- 3. RENME PS襤KOLOJ襤S襤 (H襤PERPARAMETRELER) ---\n",
    "learning_rate = 0.1      \n",
    "discount_factor = 0.9    \n",
    "epsilon = 1.0            \n",
    "epsilon_decay = 0.995    \n",
    "min_epsilon = 0.01       \n",
    "episodes = 2000          \n",
    "\n",
    "def step(state, action):\n",
    "    \"\"\"Ajan覺n fiziksel olarak ad覺m att覺覺 ve kar覺l覺覺nda 癟evreden tokat veya eker yedii yer.\"\"\"\n",
    "    row = state // GRID_SIZE\n",
    "    col = state % GRID_SIZE\n",
    "    \n",
    "    if action == 0 and col > 0: col -= 1          \n",
    "    elif action == 1 and col < GRID_SIZE - 1: col += 1  \n",
    "    elif action == 2 and row > 0: row -= 1          \n",
    "    elif action == 3 and row < GRID_SIZE - 1: row += 1  \n",
    "    \n",
    "    new_state = row * GRID_SIZE + col\n",
    "    \n",
    "    if new_state == GOAL_STATE:\n",
    "        return new_state, GOAL_REWARD, True   \n",
    "    elif new_state == SEVERE_TRAP:\n",
    "        return new_state, TRAP_PENALTY, True  \n",
    "    else:\n",
    "        return new_state, LIVING_PENALTY, False \n",
    "\n",
    "# --- 4. E襤T襤M KAMPI BALIYOR ---\n",
    "print(\"\\nAjan labirente b覺rak覺ld覺... Kendi kendine 繹reniyor, l羹tfen bekleyin...\")\n",
    "for episode in range(episodes):\n",
    "    state = START_STATE\n",
    "    done = False\n",
    "    step_count = 0 \n",
    "    \n",
    "    while not done and step_count < 100:\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.randint(0, NUM_ACTIONS - 1)\n",
    "        else:\n",
    "            action = np.argmax(q_table[state, :])\n",
    "            \n",
    "        new_state, reward, done = step(state, action)\n",
    "        \n",
    "        max_future_q = np.max(q_table[new_state, :]) \n",
    "        current_q = q_table[state, action]           \n",
    "        \n",
    "        new_q = current_q + learning_rate * (reward + discount_factor * max_future_q - current_q)\n",
    "        q_table[state, action] = new_q\n",
    "        \n",
    "        state = new_state\n",
    "        step_count += 1\n",
    "        \n",
    "    epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "\n",
    "print(\"Eitim Tamamland覺! Ajan labirentin efendisi oldu.\")\n",
    "\n",
    "# --- 5. SINAV ANI: REND襤襤 EN 襤Y襤 ROTAYI VE PUANINI BULALIM ---\n",
    "optimal_path = set()\n",
    "curr_state = START_STATE\n",
    "step_limit = 0\n",
    "total_score = 0  # Ajan覺n toplad覺覺 puanlar覺 burada biriktireceiz\n",
    "\n",
    "print(\"\\n--- SINAV SONULARI ---\")\n",
    "\n",
    "while curr_state != GOAL_STATE and curr_state != SEVERE_TRAP and step_limit < NUM_STATES * 2:\n",
    "    optimal_path.add(curr_state)\n",
    "    best_act = np.argmax(q_table[curr_state, :])\n",
    "    \n",
    "    # Ad覺m覺 at, yeni kareyi ve o karedeki DL/CEZAYI (reward) al\n",
    "    curr_state, reward, _ = step(curr_state, best_act)\n",
    "    \n",
    "    # Cebe giren puan覺 toplam puana ekle\n",
    "    total_score += reward\n",
    "    step_limit += 1\n",
    "\n",
    "print(f\"Toplam At覺lan Ad覺m: {step_limit}\")\n",
    "print(f\"Ajan覺n Bu Kusursuz Rotadan Toplad覺覺 Net Puan: {total_score}\")\n",
    "if total_score > 0:\n",
    "    print(\"Yorum: Harika! Ajan yolda yedii -1 cezalara ramen g羹n羹n sonunda k璽ra ge癟ti.\")\n",
    "else:\n",
    "    print(\"Yorum: Ajan hedefe ulasa bile yolda 癟ok fazla ad覺m att覺覺 veya tuzaa d羹t羹羹 i癟in zararda!\")\n",
    "\n",
    "# --- 6. GRSEL LEN (MATPLOTLIB) ---\n",
    "print(\"\\nHarita 癟iziliyor...\")\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.set_xlim(0, GRID_SIZE)\n",
    "ax.set_ylim(0, GRID_SIZE)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "grid_matrix = np.zeros((GRID_SIZE, GRID_SIZE))\n",
    "sns.heatmap(grid_matrix, cmap=\"Blues\", cbar=False, linewidths=2, linecolor='black', ax=ax, alpha=0.1)\n",
    "\n",
    "action_arrows = {\n",
    "    0: (-0.3, 0),    \n",
    "    1: (0.3, 0),     \n",
    "    2: (0, -0.3),    \n",
    "    3: (0, 0.3)      \n",
    "}\n",
    "\n",
    "for state in range(NUM_STATES):\n",
    "    row, col = state // GRID_SIZE, state % GRID_SIZE\n",
    "    center_x, center_y = col + 0.5, row + 0.5\n",
    "    \n",
    "    if state == START_STATE:\n",
    "        ax.text(center_x, center_y - 0.3, \"BALANGI\", ha='center', va='center', color='blue', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    if state == GOAL_STATE:\n",
    "        ax.add_patch(plt.Rectangle((col, row), 1, 1, color='lightgreen'))\n",
    "        ax.text(center_x, center_y, f\"DL\\n(+{GOAL_REWARD})\", ha='center', va='center', color='darkgreen', fontweight='bold')\n",
    "        continue \n",
    "        \n",
    "    if state == SEVERE_TRAP:\n",
    "        ax.add_patch(plt.Rectangle((col, row), 1, 1, color='salmon'))\n",
    "        ax.text(center_x, center_y, f\"TUZAK\\n({TRAP_PENALTY})\", ha='center', va='center', color='darkred', fontweight='bold')\n",
    "        continue \n",
    "\n",
    "    best_action = np.argmax(q_table[state, :])\n",
    "    \n",
    "    if np.max(q_table[state, :]) == 0 and np.min(q_table[state, :]) == 0:\n",
    "        continue \n",
    "        \n",
    "    dx, dy = action_arrows[best_action]\n",
    "    \n",
    "    is_main_path = state in optimal_path\n",
    "    \n",
    "    arrow_color = 'red' if is_main_path else 'lightgray'\n",
    "    arrow_width = 0.15 if is_main_path else 0.05\n",
    "    line_width = 3 if is_main_path else 1\n",
    "    \n",
    "    ax.arrow(center_x - dx/2, center_y - dy/2, dx, dy, \n",
    "             head_width=arrow_width, head_length=arrow_width, \n",
    "             fc=arrow_color, ec=arrow_color, lw=line_width)\n",
    "\n",
    "plt.title(f\"Ajan覺n Bulduu Ana Rota (Toplam Puan: {total_score})\", fontsize=14, fontweight='bold', pad=15)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
